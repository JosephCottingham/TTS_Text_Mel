import os
import json
from datetime import datetime

import wavio

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

from tensorflow_tts.inference import TFAutoModel, AutoProcessor
from tensorflow_tts.utils import utils

class Trainer():
    save_paths = {}

    test_strings = [
        'Hello my name is Joe. Nice to meet you!',
        'Hello my name is Joey. Nice to meet you!',
        'The quick fox jumps over lazy dog.',
        'To be or not to be.',
        'How was your day honey.',
        'This weekend will be fun!'
    ]

    def __init__(
        self,
        config,
        STRATEGY,
        steps=0,
        epochs=0,
        batches=0
    ):

        self.config = config
        self.STRATEGY = STRATEGY

        # Configure Save Paths
        self.save_paths['base'] = os.path.join(self.config["outdir"], datetime.now().strftime("%Y%m%d-%H%M%S"))
        self.save_paths['checkpoints'] = os.path.join(self.save_paths['base'], 'checkpoints')
        self.save_paths['predictions'] = os.path.join(self.save_paths['base'], 'predictions')
        self.save_paths['dataset_representations'] = os.path.join(self.save_paths['base'], 'dataset_representations')
        self.save_paths['tensorboard'] = os.path.join(self.save_paths['base'], 'tensorboard')
        for path_key in self.save_paths.keys():
            os.makedirs(self.save_paths[path_key], exist_ok=True)

        # Set start location
        self.steps = steps
        self.epochs = epochs
        self.batches = batches

        self.writer = tf.summary.create_file_writer(self.save_paths['tensorboard'])
        
        self.list_metrics_name = [
            "adv_loss",
            "fm_loss",
            "gen_loss",
            "real_loss",
            "fake_loss",
            "dis_loss",
        ]

        self.train_metrics = {}
        for name in self.list_metrics_name:
            self.train_metrics.update(
                {name: tf.keras.metrics.Mean(name="train_" + name, dtype=tf.float32)}
            )

        self.melgan = TFAutoModel.from_pretrained("tensorspeech/tts-melgan-ljspeech-en", name="melgan")
        self.tacotron2_processor = AutoProcessor.from_pretrained("tensorspeech/tts-tacotron2-ljspeech-en")

    def update_current_loss_metrics(self, dict_metrics_losses):
        for name, value in dict_metrics_losses.items():
            self.train_metrics[name].update_state(value)

    def _check_save_interval(self):
        """Save interval checkpoint."""
        if self.steps % self.config["save_interval_steps"] == 0:
            self.save_checkpoint()
            print(f"Successfully saved checkpoint @ {self.steps} steps.")

    def _check_log_interval(self, batch):
        """Log to tensorboard."""
        if self.steps % self.config["log_interval_steps"] == 0:
            for metric_name in self.list_metrics_name:
                print(f"(Step: {self.steps}) train_{metric_name} = {self.train_metrics[metric_name].result():.4f}.")
            self._write_to_tensorboard(self.train_metrics, stage="train")
            self.track_intermediate_progress(batch)

    def _write_to_tensorboard(self, list_metrics, stage="train"):
        """Write variables to tensorboard."""
        with self.writer.as_default():
            for key, value in list_metrics.items():
                tf.summary.scalar(stage + "/" + key, value.result(), step=self.steps)
                self.writer.flush()

    def padd_slice_mel_output(self, mel_outputs):
        """Accepts of Mel Spectgram Tensor of Varaible Length
        and Padd/Slices to fit training data max length

        Args:
            mel_outputs (Tensor): Tensor Containing Mel Data

        Returns:
            Tensor: Tensor Containing Mel Data of fixed length
        """
        mel_outputs_shape = mel_outputs.get_shape()
        add = self.config["max_mel_length"] - mel_outputs_shape[1]
        # Checks if padding/slicing is required
        if add < 0:
            mel_outputs = tf.slice(mel_outputs, [0,0,0], [mel_outputs_shape[0], self.config["max_mel_length"], mel_outputs_shape[2]])
        else:
            paddings = tf.constant([[0, 0], [0, add], [0,0]])
            mel_outputs = tf.pad(mel_outputs, paddings, "CONSTANT")
        
        return mel_outputs

    def _train_batch(self, batch):
        """Proforms traing on one batch

        Args:
            batch (dict): dict as generated by the dataset. Structed as the following
            Note that each nested element is a signle data sample/step.
            {
                'input_ids':list(list())
                'input_lengths':list(list())
                'speaker_ids':list(list())
                'mel_gts':list(list())
                'mel_lengths':list(list())
            }
        """
        print(f'Epoch: {self.epochs}')
        print(f'Steps: {self.steps}')
        print(f'Batches: {self.batches}')

        # Holds loss values that sould be saved to tensorboard
        dict_metrics_losses = {}

        # Train Generator
        adv_loss, fm_loss, generated_mel = self.train_generator(batch)
        
        # Store Loss Values for generator
        dict_metrics_losses['adv_loss'] = adv_loss
        dict_metrics_losses['fm_loss'] = fm_loss
        dict_metrics_losses['gen_loss'] = adv_loss

        # Train discrimator, run sepratly because of shown improved outcomes
        real_loss = self.train_discriminator(batch['mel_gts'], True)
        fake_loss = self.train_discriminator(generated_mel, False)

        # Store Loss Values for discrimator
        dict_metrics_losses['real_loss'] = real_loss
        dict_metrics_losses['fake_loss'] = fake_loss
        dict_metrics_losses['dis_loss'] = fake_loss + real_loss

        # Update the current loss metrices to be stored when config contions are met
        self.update_current_loss_metrics(dict_metrics_losses)

        # Incease the current step count
        self.steps += self.config['dataset_manager_params']['batch_size']

    def train_generator(self, batch):
        """Trains generator on give batch

        Args:
            batch (dict): dict as generated by the dataset. Structed as the following
            Note that each nested element is a signle data sample/step.
            {
                'input_ids':list(list())
                'input_lengths':list(list())
                'speaker_ids':list(list())
                'mel_gts':list(list())
                'mel_lengths':list(list())
            }

        Returns:
            tuple: Losses and generated mel spectrugrams
                0: adversal_loss
                1: feature maping loss
                2: generated mel spectrugrams
        """

        with tf.GradientTape() as gtape:
            
            # Generate mel spectrograms for batch
            (
                decoder_output,
                mel_outputs,
                stop_token_predictions,
                alignment_historys,
            ) = self._generator(
                batch,
                training=False
            )
            
            # Slice or Padd the variable length output of the generator                
            mel_outputs = self.padd_slice_mel_output(mel_outputs)
            
            # Generate discriminator results for real and generated data
            p_dis_gen = self._discriminator(mel_outputs)
            p_dis_real = self._discriminator(batch['mel_gts'])

            # Calulate Feature Maping Loss
            fm_loss = self.mae_loss(p_dis_real, p_dis_gen)
            # Calulate Aversal Loss
            adv_loss = self.mse_loss(tf.ones_like(p_dis_real), p_dis_gen)


            adv_loss += self.config["lambda_feat_match"]* fm_loss
            
            value_not_nan = tf.dtypes.cast(tf.math.logical_not(tf.math.is_nan(adv_loss)), dtype=tf.float32)
            adv_loss = tf.math.multiply_no_nan(adv_loss, value_not_nan)

            # Confirm gradientTape is watching important 
            gtape.watch(self._generator.trainable_weights)
            gtape.watch(adv_loss)


            # Aviable to more clealy select which layers to cal and apply gradient too
            # Note that base_model layers do not apear in the list of layers
            grad_adv_loss = adv_loss
            grad_layers = self._generator.trainable_weights

            # Calucate the gradients based on current weights and loss for each layer
            gradients = gtape.gradient(
                grad_adv_loss, grad_layers
            )

            # Apply the gradients to each layer
            self._gen_optimizer.apply_gradients(
                zip(gradients, grad_layers)
            )


        return adv_loss, fm_loss, mel_outputs


    def train_discriminator(self, x, real):
        # print(f'train_discriminator {self.steps}')

        batch_loss = 0.0
        with tf.GradientTape() as gtape:
            
            # generated prediction list
            predictions = self._discriminator(x)

            # Generate correct classifcation list, zero for real, one for generated
            expected_predictions = tf.zeros_like(predictions) if real else tf.ones_like(predictions)
            
            # 
            loss = self.mse_loss(expected_predictions, predictions)

            gtape.watch(self._discriminator.trainable_variables)
            gtape.watch(loss)
            
            gradients = gtape.gradient(
                loss, self._discriminator.trainable_variables
            )

            self._dis_optimizer.apply_gradients(
                zip(gradients, self._discriminator.trainable_variables)
            )


        return loss

    def _train_epoch(self):
        """Train one epoch / one loop of all train data
        """
        for train_steps_per_epoch, batch in enumerate(self.train_data_loader, 1):
            
            # Perform training on batch
            self.STRATEGY.run(self._train_batch, args=(batch,))

            # Check for loging and saving checkpoint
            self._check_log_interval(batch)
            self._check_save_interval()

            # Interate on complete batch
            self.batches += 1

            
        # Interate on complete epoch
        self.epochs += 1

    
        
    def fit(self, train_data_manager, valid_data_manager, resume_path=None):
        dir = os.path.join(self.save_paths['dataset_representations'], 'train')
        os.makedirs(dir)
        train_data_manager.data_graphics(dir)
        dir = os.path.join(self.save_paths['dataset_representations'], 'valid')
        os.makedirs(dir)
        valid_data_manager.data_graphics(dir)
        self.train_data_loader = train_data_manager.create()
        self.valid_data_loader = valid_data_manager.create()

        self.create_checkpoint_manager(max_to_keep=10000)
        if resume_path != None:
            self.load_checkpoint(resume_path)
            logging.info(f"Successfully resumed from {resume_path}.")

        while True:
            print('--Stats--')
            print(f'Steps: {self.steps}')
            print(f'Epoch: {self.epochs}')
            self._train_epoch()

            if self.epochs >= self.config['train_max_epochs']:
                print('train_complete')
                break

            self.save_checkpoint()


    def compile(self, gen_model, dis_model, gen_optimizer, dis_optimizer):
        self._generator = gen_model
        self._discriminator = dis_model
        self._gen_optimizer = gen_optimizer
        self._dis_optimizer = dis_optimizer

        self.binary_crossentropy = tf.keras.losses.BinaryCrossentropy(
            from_logits=True, reduction=tf.keras.losses.Reduction.NONE
        )
        self.mse_loss = tf.keras.losses.MeanSquaredError(
            reduction=tf.keras.losses.Reduction.NONE
        )
        self.mae_loss = tf.keras.losses.MeanAbsoluteError(
            reduction=tf.keras.losses.Reduction.NONE
        )

    def create_checkpoint_manager(self, max_to_keep=10):
        """Create checkpoint management."""

        self.ckpt = tf.train.Checkpoint(
            steps=tf.Variable(1),
            epochs=tf.Variable(1),
            gen_optimizer=self._gen_optimizer,
            dis_optimizer=self._dis_optimizer,
        )
        self.ckp_manager = tf.train.CheckpointManager(
            self.ckpt, self.save_paths['checkpoints'], max_to_keep=max_to_keep
        )

    def save_checkpoint(self):
        """Save checkpoint."""
        self.ckpt.steps.assign(self.steps)
        self.ckpt.epochs.assign(self.epochs)
        self.ckp_manager.save(checkpoint_number=self.steps)

        utils.save_weights(
            self._generator,
            os.path.join(self.save_paths['checkpoints'], f'generator-{self.steps}.h5')
        )

        utils.save_weights(
            self._discriminator,
            os.path.join(self.save_paths['checkpoints'], f'discriminator-{self.steps}.h5')
        )

    def load_checkpoint(self, pretrained_path):
        """Load checkpoint."""
        self.ckpt.restore(pretrained_path)
        self.steps = self.ckpt.steps.numpy()
        self.epochs = self.ckpt.epochs.numpy()
        self._gen_optimizer = self.ckpt.gen_optimizer
        # re-assign iterations (global steps) for gen_optimizer.
        self._gen_optimizer.iterations.assign(tf.cast(self.steps, tf.int64))
        # re-assign iterations (global steps) for dis_optimizer.
        try:
            discriminator_train_start_steps = self.config["discriminator_train_start_steps"]
            discriminator_train_start_steps = tf.math.maximum(
                0, self.steps - discriminator_train_start_steps 
            )
        except Exception:
            discriminator_train_start_steps = self.steps
        self._dis_optimizer = self.ckpt.dis_optimizer
        self._dis_optimizer.iterations.assign(
            tf.cast(discriminator_train_start_steps, tf.int64)
        )

        # load weights.
        utils.load_weights(
            self._generator,
            os.path.join(self.save_paths['checkpoints'], f'generator-{self.steps}.h5')
        )
        utils.load_weights(
            self._discriminator,
            os.path.join(self.save_paths['checkpoints'], f'discriminator-{self.steps}.h5')
        )


    def track_intermediate_progress(self, batch):

        # Generate example output based on batch of data
        (
            decoder_output,
            mel_outputs,
            stop_token_predictions,
            alignment_historys,
        ) = self._generator(batch, training=False)
        
        # Get real data and sample id
        mel_gts = batch["mel_gts"]
        utt_ids = batch["utt_ids"]

        # convert to tensor.
        try:
            mels_before = decoder_output.values[0].numpy()
            mels_after = mel_outputs.values[0].numpy()
            mel_gts = mel_gts.values[0].numpy()
            alignment_historys = alignment_historys.values[0].numpy()
            utt_ids = utt_ids.values[0].numpy()
        except Exception:
            mels_before = decoder_output.numpy()
            mels_after = mel_outputs.numpy()
            mel_gts = mel_gts.numpy()
            alignment_historys = alignment_historys.numpy()
            utt_ids = utt_ids.numpy()

        # check directory
        base_dirname = os.path.join(self.save_paths['predictions'], f'{self.steps}-steps')
        os.makedirs(base_dirname)

        img_dirname = os.path.join(self.save_paths['predictions'], 'img')
        audio_dirname = os.path.join(self.save_paths['predictions'], 'audio')
        os.makedirs(img_dirname)
        os.makedirs(audio_dirname)

        # For each sample/step in the batch generate figure showing comparison between real and generated
        for idx, (mel_gt, mel_before, mel_after, alignment_history) in enumerate(zip(mel_gts, mels_before, mels_after, alignment_historys), 0):
            mel_gt = tf.reshape(mel_gt, (-1, 80)).numpy()  # [length, 80]
            mel_before = tf.reshape(mel_before, (-1, 80)).numpy()  # [length, 80]
            mel_after = tf.reshape(mel_after, (-1, 80)).numpy()  # [length, 80]

            # plot figure and save it
            utt_id = utt_ids[idx]
            figname = os.path.join(img_dirname, f"{utt_id}.png")
            fig = plt.figure(figsize=(10, 8))
            ax1 = fig.add_subplot(311)
            ax2 = fig.add_subplot(312)
            ax3 = fig.add_subplot(313)
            im = ax1.imshow(np.rot90(mel_gt), aspect="auto", interpolation="none")
            ax1.set_title("Target Mel-Spectrogram")
            fig.colorbar(mappable=im, shrink=0.65, orientation="horizontal", ax=ax1)
            ax2.set_title(f"Predicted Mel-before-Spectrogram @ {self.steps} steps")
            im = ax2.imshow(np.rot90(mel_before), aspect="auto", interpolation="none")
            fig.colorbar(mappable=im, shrink=0.65, orientation="horizontal", ax=ax2)
            ax3.set_title(f"Predicted Mel-after-Spectrogram @ {self.steps} steps")
            im = ax3.imshow(np.rot90(mel_after), aspect="auto", interpolation="none")
            fig.colorbar(mappable=im, shrink=0.65, orientation="horizontal", ax=ax3)
            plt.tight_layout()
            plt.savefig(figname)
            plt.close()

            # plot alignment
            figname = os.path.join(img_dirname, f"{idx}_alignment.png")
            fig = plt.figure(figsize=(8, 6))
            ax = fig.add_subplot(111)
            ax.set_title(f"Alignment @ {self.steps} steps")
            im = ax.imshow(
                alignment_history, aspect="auto", origin="lower", interpolation="none"
            )
            fig.colorbar(im, ax=ax)
            xlabel = "Decoder timestep"
            plt.xlabel(xlabel)
            plt.ylabel("Encoder timestep")
            plt.tight_layout()
            plt.savefig(figname)
            plt.close()


        # Generate Waveform
        # print(mel_outputs[idx].get_shape())
        # filename = os.path.join(dirname, f"training_data_audio_sample.wav")
        # audio = self.melgan(mel_outputs)[0, :, 0].numpy()
        # wavio.write(filename, audio, 22050, sampwidth=3)

        # Generate and save standard sample
        for index, sample in enumerate(self.test_strings):
            # Encode string into expected dec list
            input_ids = self.tacotron2_processor.text_to_sequence(sample)

            # Generate Mel Spectrograms
            _, mel_outputs, stop_token_prediction, alignment_history = self._generator.inference(
                tf.expand_dims(tf.convert_to_tensor(input_ids, dtype=tf.int32), 0),
                tf.convert_to_tensor([len(input_ids)], tf.int32),
                tf.convert_to_tensor([0], dtype=tf.int32)
            )

            # Take generated melspectrogram and run though the melgan model to generate a waveform from it
            audio = self.melgan(mel_outputs)[0, :, 0].numpy()

            # Save as wav file to be used to see status
            filename = os.path.join(audio_dirname, f'sample_{index}.wav')
            wavio.write(filename, audio, 22050, sampwidth=3)

            # Write what the string is to a corrisponding file
            filename = os.path.join(audio_dirname, f'sample_{index}.txt')
            txt_file = open(filename, "w")
            txt_file.write(sample)
            txt_file.close()